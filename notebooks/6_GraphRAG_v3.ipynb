{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests python-dotenv neo4j pydantic langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "from pydantic import BaseModel, Field\n",
    "import warnings\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_request(url):\n",
    "  return requests.get(url).json()\n",
    "\n",
    "def strip_html(text):\n",
    "  \"\"\" remove HTML tags from a string \"\"\"\n",
    "  if not isinstance(text, str):\n",
    "    return \"\"\n",
    "  clean = re.compile(\"<.*?>\")\n",
    "  return re.sub(clean, \"\", text)\n",
    "\n",
    "def preprocess_events(events):\n",
    "  \"\"\" construct dictionary from event data \"\"\"\n",
    "  return [\n",
    "    {\n",
    "      \"title\": event[\"title\"],\n",
    "      \"group_title\": event[\"group_title\"],\n",
    "      \"url\": event[\"url\"],\n",
    "      \"description\": strip_html(event[\"description\"]),\n",
    "      \"date\": event[\"date\"],\n",
    "      \"date_time\": event[\"date_time\"],\n",
    "      \"location\": event[\"location\"],\n",
    "      \"location_title\": event[\"location_title\"],\n",
    "      \"location_latitude\": float(event[\"location_latitude\"]) if event[\"location_latitude\"] != None else 0,\n",
    "      \"location_longitude\": float(event[\"location_longitude\"]) if event[\"location_longitude\"] != None else 0,\n",
    "      \"cost\": event[\"cost\"],\n",
    "      \"thumbnail\": event[\"thumbnail\"],\n",
    "      \"event_types\": event[\"event_types\"],\n",
    "      \"event_types_audience\": event[\"event_types_audience\"],\n",
    "    }\n",
    "    for event in events\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_root = os.path.join(os.getcwd(), 'graphrag_index')\n",
    "os.makedirs(os.path.join(index_root, 'input'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamu_events_url = \"https://calendar.tamu.edu/live/json/events/group\"\n",
    "raw_events = get_json_request(tamu_events_url)\n",
    "processed_events = preprocess_events(raw_events)\n",
    "\n",
    "#save processed data to file\n",
    "file_path = \"inputEvents.txt\"\n",
    "with open(file_path, 'w') as file:\n",
    "    for j, event in enumerate(processed_events):\n",
    "        file.write(json.dumps(event) + \"\\n\")\n",
    "        if j == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_docs = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        loaded_docs.append(line.strip())\n",
    "\n",
    "documents = loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up Neo4j database connection\n",
    "driver = GraphDatabase.driver(\n",
    "    uri=os.environ[\"NEO4J_URI\"],\n",
    "    auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index already exists or there was an error: {code: Neo.ClientError.Security.Unauthorized} {message: The client is unauthorized due to authentication failure.}\n"
     ]
    }
   ],
   "source": [
    "def create_fulltext_index(tx):\n",
    "    query = '''\n",
    "    CREATE FULLTEXT INDEX fulltext_entity_name \n",
    "    FOR (n:Entity) \n",
    "    ON EACH [n.name];\n",
    "    '''\n",
    "    tx.run(query)\n",
    "\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "\n",
    "try:\n",
    "    create_index()\n",
    "except Exception as e:\n",
    "    print(\"The index already exists or there was an error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityItem(BaseModel):\n",
    "    name: str\n",
    "    type: str\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    names: List[EntityItem] = Field(\n",
    "        ...,\n",
    "        description=\"List of entities with 'name' and 'type', focusing on event-related entities.\"\n",
    "    )\n",
    "    \n",
    "def extract_entities(text):\n",
    "    prompt = f\"\"\"\n",
    "    Find relevant entities in the following text, extracting \"Event\", \"Event_Type\", \n",
    "    \"Event_Types_Audience\", \"Speakers\", \"Location\", \"Department_or_Organization\", \"Topic\", and \n",
    "    \"Date\" entities. Format the output as a JSON list, where each item has 'name' and 'type' keys.\n",
    "    \n",
    "    Note that for Event_Type, the possible types are only: Campus Life; Training & Workshops;\n",
    "    Sports & Athletics; Speakers, Forums, and Conferences; Deadlines; General Interest; Academic \n",
    "    Calendar; Arts & Entertainment; and International Students.\n",
    "    \n",
    "    For Event_Types_Audience, the possible audiences are only: Students, Researcher, Staff, and/or\n",
    "    Faculty.\n",
    "\n",
    "    Do not add any extra explanation or commentary, just the output specified above.\n",
    "    Create a list of entities with `name` and `type` fields, ensuring that each entity has a \n",
    "    non-null `name` value. If you can't find the `name`, do not include the entity in the response.\n",
    "\n",
    "    For example:\n",
    "\n",
    "    Text: \"title\": \"ICF Open\", \"group_title\": \"Department of Rec Sports\", \"url\": \"\", \n",
    "    \"description\": \"\", \"date\": \"November 7\", \"date_time\": \"3:00pm - 10:00pm\", \"location\": null, \n",
    "    \"location_title\": null, \"location_latitude\": 0, \"location_longitude\": 0, \"cost\": null,\n",
    "    \"thumbnail\": null, \"event_types\": null, \"event_types_audience\": null\n",
    "\n",
    "    Your response:\n",
    "\n",
    "    [\n",
    "        {{\n",
    "            \"name\": \"ICF Open\",\n",
    "            \"type\": \"Event\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"Department of Rec Sports\",\n",
    "            \"type\": \"Department_or_Organization\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"November 7\",\n",
    "            \"type\": \"Date\"\n",
    "        }}\n",
    "    ]\n",
    "    \n",
    "    Text: \"What tech events are happening on October 4 for researchers?\"\n",
    "    \n",
    "    Your response:\n",
    "    \n",
    "    [\n",
    "        {{\n",
    "            \"name\": \"Department of Computer Science and Engineering\",\n",
    "            \"type\": \"Department_or_Organization\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"Technology\",\n",
    "            \"type\": \"Topic\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"October 4\",\n",
    "            \"type\": \"Date\"\n",
    "        }},\n",
    "        {{\n",
    "            \"name\": \"Researcher\",\n",
    "            \"type\": \"Event_Types_Audience\"\n",
    "        }}        \n",
    "    ]\n",
    "    \n",
    "    Your response should be formatted like above, with only a single pair of\n",
    "    square brackets and curly brackets used internally.\n",
    "\n",
    "    Text: \"{text}\"\n",
    "    \"\"\"\n",
    "    \n",
    "    llm = Ollama(model=\"llama3.1\", temperature=0.0, num_predict=1000)\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    print(\"llm response:\")\n",
    "    print(response)\n",
    "\n",
    "    try:\n",
    "        raw_entities = json.loads(response.strip())\n",
    "\n",
    "        #ensure all entities have a 'name'\n",
    "        valid_entities = []\n",
    "        for entity in raw_entities:\n",
    "            name = entity.get('name')\n",
    "            if isinstance(name, list):\n",
    "                #if name is a list, concatenate it into a single string\n",
    "                entity['name'] = \", \".join(name)\n",
    "            elif not isinstance(name, str):\n",
    "                continue\n",
    "\n",
    "            if isinstance(entity['name'], str):\n",
    "                valid_entities.append(entity)\n",
    "\n",
    "        entities = Entities.parse_obj({\"names\": valid_entities})\n",
    "        return entities\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing entities: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#insert documents with extracted entities into the graph\n",
    "def add_document_to_graph(document, entities):\n",
    "    with driver.session() as session:\n",
    "        for entity in entities.names:\n",
    "            # set the Cypher query with the label based on entity type\n",
    "            #NEED TO CHANGE LATER**********\n",
    "            query = f\"\"\"\n",
    "            MERGE (e:{entity.type} {{name: $name}})\n",
    "            MERGE (d:Document {{text: $text}})\n",
    "            MERGE (d)-[:MENTIONS]->(e)\n",
    "            \"\"\"\n",
    "            \n",
    "            session.run(query, name=entity.name, text=document)\n",
    "\n",
    "#process documents\n",
    "for doc in documents:\n",
    "    entities = extract_entities(doc)\n",
    "    # print(\"extracted entities:\", entities)\n",
    "    add_document_to_graph(doc, entities)\n",
    "\n",
    "# print(\"extracted entities:\", entities)\n",
    "# print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "llm = Ollama(model=\"llama3.1\", temperature=0.0, num_predict=500)\n",
    "\n",
    "def graph_retriever(question: str):\n",
    "    result = \"\"\n",
    "    entities = extract_entities(question)  # extract entities from the question\n",
    "    \n",
    "    entity_terms = []\n",
    "    for entity in entities.names:\n",
    "        #split compound terms and add both full and partial terms\n",
    "        entity_terms.extend([\n",
    "            term.lower() for term in entity.name.split()\n",
    "        ])\n",
    "    \n",
    "    if entity_terms:\n",
    "        response = driver.session().run(\n",
    "            \"\"\"\n",
    "            MATCH (e:Event)\n",
    "            CALL {\n",
    "                WITH e\n",
    "                MATCH (e)-[:MENTIONS*1..2]-(related)\n",
    "                WHERE related.text IS NOT NULL OR related.name IS NOT NULL\n",
    "                RETURN COLLECT(DISTINCT COALESCE(related.text, related.name)) as relatedTexts\n",
    "            }\n",
    "            WITH e, relatedTexts, [text IN relatedTexts WHERE text IS NOT NULL | toLower(text)] as lowerTexts\n",
    "            WITH e, relatedTexts, lowerTexts,\n",
    "                // Calculate a match score based on how many terms are found\n",
    "                size([term IN $query_terms WHERE \n",
    "                    toLower(e.name) CONTAINS term\n",
    "                    OR ANY(text IN lowerTexts WHERE text CONTAINS term)\n",
    "                ]) as matchScore\n",
    "            WHERE matchScore > 0  // At least one term must match\n",
    "            RETURN \n",
    "                'Event: ' + e.name + \n",
    "                '\\nMatch Score: ' + toString(matchScore) + '/' + toString(size($query_terms)) +\n",
    "                '\\nContext: ' + \n",
    "                reduce(s = \"\", text IN relatedTexts | s + \"\\n- \" + text) as output\n",
    "            ORDER BY matchScore DESC  // Show best matches first\n",
    "            \"\"\",\n",
    "            {\"query_terms\": entity_terms}\n",
    "        )\n",
    "\n",
    "        result += \"\\n\".join([el['output'] for el in response if el['output'] is not None])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following graph data, answer the user's question within 450 words.\n",
    "    Do not mention the graph, just focus on answering the user's question.\n",
    "    \n",
    "    Graph data:\n",
    "    {result}\n",
    "    \n",
    "    Question:\n",
    "    '{question}'\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"results:\")\n",
    "    print(result)\n",
    "    \n",
    "    #generate a response using the LLM\n",
    "    llm_response = llm.invoke(prompt).strip()\n",
    "    \n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "print(graph_retriever(\"What athletics events are happening?\"))\n",
    "#possibly implement: LLM should be able to modify Cypher query if necessary?*****\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
